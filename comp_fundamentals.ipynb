{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def99f44",
   "metadata": {},
   "source": [
    "# 1. Computation fundamentals\n",
    "\n",
    "There are several sources of errors in computation: \n",
    "\n",
    "- **stability**, a property of the algorithm,\n",
    "- **conditioning**, a property of the problem, and\n",
    "- **roundoff**, a consequence of the representation of numbers we use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e05c2f",
   "metadata": {},
   "source": [
    "## Floating-point arithmetic\n",
    "\n",
    "Computers work in terms of floating-point numbers instead of reals $\\mathbb{R}$. \n",
    "\n",
    "Let's say $\\circ$ is an operator that rounds the real number $x \\in \\mathbb{R}$ to the nearest floating-point number $\\hat{x}$:\n",
    "\n",
    "$$ \\hat{x} := \\circ x. $$\n",
    "\n",
    "The _absolute_ error induced by this representation is\n",
    "\n",
    "$$ \\Delta x = \\circ x - x = \\hat{x} - x, $$\n",
    "and the _relative_ error is\n",
    "\n",
    "$$ \\delta x = \\frac{\\Delta x}{x} = \\frac{\\hat{x} - x}{x}. $$\n",
    "We can rearrange this as\n",
    "\n",
    "$$ \\hat{x} = (1 + \\delta x)x. $$\n",
    "\n",
    "The IEEE (Institute of Electrical and Electronics Engineers) standard _guarantees_ that \n",
    "\n",
    "$$ |\\delta x| < \\mu_M = \\tfrac{1}{2}\\varepsilon_M, $$\n",
    "where $\\varepsilon_M$ is **machine precision**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c2624",
   "metadata": {},
   "source": [
    "```{admonition} Question\n",
    "Where does $\\varepsilon_M$ come from, and what is it in single and double precision arithmetic?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97724428",
   "metadata": {},
   "source": [
    "Numbers in floating-point arithmetic are represented as\n",
    "\n",
    "$$ \\pm (1 + f) \\cdot 2^n, $$ \n",
    "where $n$ is the **exponent** and $(1+f)$ is the **mantissa**. \n",
    "- $d$ is a constant called the binary _precision_.\n",
    "\n",
    "A fixed number of bits called the binary **precision**, denoted $d$, is then used to store $f$ in base 2:\n",
    "\n",
    "$$ f = \\sum_{i = 1}^d b_i 2^{-i}, \\quad b_i \\in \\{0, 1\\}. $$\n",
    "It's useful to pull out a constant $2^{-d}$ to get\n",
    "\n",
    "$$ f = 2^{-d}\\sum{i = 1}{d} b_i 2^{d - i} = 2^{-d}z, $$\n",
    "where $z$ is now an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a423774",
   "metadata": {},
   "source": [
    "```{admonition} Question\n",
    "What values can $z$ take? How many numbers are there between $2^n$ and $2^{n+1}$? What does that say about the relationship between $\\varepsilon_M$ and $d$?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e8dc1",
   "metadata": {},
   "source": [
    "$z$ takes values in $ z \\in \\{0, 1, 2, \\ldots, 2^{d} - 1\\}$, therefore there are $2^d$ integers between two adjacent powers of $2$ in floating-point arithmetic. From this we can read off that\n",
    "\n",
    "$$ \\varepsilon_M = 2^{-d}. $$\n",
    "In single precision, $d = 23$ bits are used to represent the mantissa, therefore $\\varepsilon_M \\approx 2\\cdot 10^{-7}$ and from $\\mu_M$ we expect each number to be accurate to around 7 digits. For double precision, $d = 52$ and numbers can be trusted to 16 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0899597",
   "metadata": {},
   "source": [
    "## Condition number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd4a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
